American Stock Analysis
This project is aimed to get a specific company's financial statements of America from U.S. Securities And Exchange Commission (SEC), including

Consolidated statements of operations (income statements)
Consolidated balance sheet
Consolidated statement of cash flows
Besides getting information about the company's financial statements, some important indicators such as ROA, gross margin, etc, are also calculated and the visualization of them is accomplished subsequently.

Financial statements of the targeted company is obtained from 10-K and 10-Q reports, searched from EDGAR|Company Filings.

Reference:

10-k財報怎麼看？美國財報閱讀入門教學
How to Switch Tabs in Selenium For Python
What is close() and quit() commands in Selenium Webdriver?
Python Stripytime
存金融股真的好嗎？投資人該知道金融股存股的好與壞
從財報、4指標篩優質銀行股
Regular expression operations #functions


Functions definition

# Check the report type (10-K or 10-Q)
def check_report_type(soup):
    # print(str(soup))
    test_list = res = soup.find_all("ix:nonnumeric", {"id" : re.compile(r"fact-identifier-\d+")})
    # print(test)
    # test = etree.HTML(str(soup)).xpath('//*[@id="dynamic-xbrl-form"]/div[10]/table/tbody/tr[2]/td[2]/span')[0].text
    
    
    # 片立每個test才能決定是哪個報表!!
    if(any(test.string == "10-Q" for test in test_list)):
        return 'Q'
    elif(any((test.string == "10-K")for test in test_list)):
        return 'K'
    else:
        return "Drop"


# Use selenium to get information from sec.gov automatically.
# Use bs4's BeautifullSoup to parse and extract the specific data.

import requests
from bs4 import BeautifulSoup as BS
import time
from dateutil import parser
import re
from lxml import etree
import numpy as np
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys


# For test: target = APPL
# target_stock = "APPL"
target_stock = "TSLA"
# target_stock = "KO"
# target_stock = "哈哈ㄏ阿"


# Process 1: Get financial statements from SEC.gov
# Visit "EDGAR | Company Filings" of SEC.gov to search for a targeted company
print('Start connecting ...')
browser = webdriver.Edge(r"msedgedriver.exe")    # Start webdriver.exe
time.sleep(np.random.rand() + 2)    # Give 2.0 ~ 3.0 seconds for opening the webdriver.ext

url_search = "https://www.sec.gov/edgar/searchedgar/companysearch"

browser.get(url_search)
time.sleep(np.random.rand() + 2)    # Give 2.0 ~ 3.0 seconds for loading web content from server

# Find input element to enter the target stock abbreviation and press enter
stock_input = browser.find_element(By.ID, "edgar-company-person")
stock_input.send_keys(target_stock)
time.sleep(np.random.rand() + 1)

stock_input.send_keys(Keys.ENTER)
time.sleep(np.random.rand() + 2)    # Hold 2 ~ 3 seconds for loading content from server



# # Find the submit button to search for the result
# submit = browser.find_element(By.CLASS_NAME, "collapsed-submit")

# # Input the stock abbr. and submit
# stock_input.send_keys(target_stock)
# submit.click()


# Click "View all 10-Ks and 10-Qs" button
# If no matching companies is showed, then prompt retry message
find_result_check = BS(browser.page_source, "html.parser").find('div', id='contentDiv')

# if not re.search(r".*No matching companies\..*", find_result_check):
# if not re.search(r".*No matching companies\..*", ):
# if (not browser.find_element(By.XPATH, '//*[@id="contentDiv"]/div')):
if not find_result_check:
    
    
    annual_quarterly_report = browser.find_element(By.XPATH, '//*[@id="filingsStart"]/div[2]/div[3]/h5')
    annual_quarterly_report.click()
    time.sleep(np.random.rand() + 1)    # Wait for 1 ~ 2 seconds
    all_KQs = browser.find_element(By.XPATH, '//*[@id="filingsStart"]/div[2]/div[3]/div/button[1]')
    all_KQs.click()


    # To get 8 quarterly report (including 10-K reports and 10-Q reports), first 8 files needs scanned
    reports = list()  # To store 8 HTMLs of financial statements

    # Get current window handle
    # Because when clicking the linkage of report, new tab will be created. 
    # Need to switch back to the original web page to get another report of different quarter.
    # current_window = browser.current_window_handle
    # print(current_window)

    # Parameters for requests
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
    headers = {'user-agent': user_agent}


    # Get first 8 10-K or 10-Q reports
    #try:
    # Count the amount of filed reports without duplication (Reporting date must be unique)
    
    # reports_count = 8 if len(browser.find_elements(By.XPATH, '//*[@id="filingsTable"]/tbody/tr')) >= 8 else len(browser.find_elements(By.XPATH, '//*[@id="filingsTable"]/tbody/tr'))
    reports_count = len(browser.find_elements(By.XPATH, '//*[@id="filingsTable"]/tbody/tr'))
    print('reports count: ', reports_count)


    # For test
    # xpath = '//*[@id="filingsTable"]/tbody/tr[1]/td[2]/div/a[1]'
    # report_link = browser.find_element(By.XPATH, xpath)
    # time.sleep(np.random.rand() + 1)
    # report_link.click()
    
    
    # A set to store reporting date
    reporting_date = set()
    
    
    # Open financial statements of search result from SEC.gov
    for i in range(reports_count):
        xpath_date = '//*[@id="filingsTable"]/tbody/tr[' + str(i + 1) + ']/td[4]/a'
        xpath = '//*[@id="filingsTable"]/tbody/tr[' + str(i + 1) + ']/td[2]/div/a[1]'

        
        # APPL: //*[@id="filingsTable"]/tbody/tr[1]/td[4]/a
        # TSLA: //*[@id="filingsTable"]/tbody/tr[1]/td[4]/a
        #     # Record current window ID for switching between tabs of browser
        #     reports_window = browser.current_window_handle

        # args = (By.XPATH, xpath)
        
        if(len(reporting_date) < 8):
            reporting_date.add(browser.find_element(By.XPATH, xpath_date).text)
            report_link = browser.find_element(By.XPATH, xpath)
            time.sleep(np.random.rand() + 1.5)

        
            report_link.click()
            time.sleep(np.random.rand() + 2)
        
        elif(len(reporting_date) >= 8):
            break
        else:
            print("Something wrong when clicking report link!")
            break




    # Get HTMLs from web tabs
    # Record new tab of window ID, string type
    new_windows = browser.window_handles

    # Get current window handle
    current_window = browser.current_window_handle

    for window in new_windows:
        if(window != current_window):
            browser.switch_to.window(window)
            time.sleep(np.random.rand() + 1.5)
            report = BS(browser.page_source, "html.parser")
            url = browser.current_url
            date_match = re.search(r"-(\d{8})\.htm$", url)
            
            reports.append((report, url, parser.parse(date_match.group(1)) if date_match else None))
            

    
    



    """
    # This section is bulit elsewhere. It will be replaced after the program of this part is completed.
    # Process 2: Extract financial statements from the collected HTMLs
    # Format settings of dataframe
    report_data = []
    report_index = []
    report_column = []

    for report in reports:
        print(type(report))

    # Differnt type of stocks (company and financial industry)
    # Financial industry has no inventories. It's a industry earning money by money! Different measurement needs to be implyed.
    """
    


else:
    print('Execute else statement ...') 
    print('No matching companies. Please try again.')

    
      
# except:
    #print('Can not get 10-K or 10-Q reports from SEC.gov!')
# finally:
#     pass
#     browser.close()
print("End connecting ...")
browser.quit()  # Close the webdriver.exe  



# print(len(reports))
# browser.close()



Find common portion of financial reports from SEC.gov
For non-financial industry
CONSOLIDATED STATEMENTS OF INCOME (from coca cola, 10-Q/1)

CONSOLIDATED BALANCE SHEETS (from coca cola, 10-Q/1)

CONSOLIDATED STATEMENTS OF CASH FLOWS (from coca cola, 10-Q/1)

CONSOLIDATED STATEMENTS OF INCOME (from coca cola, 10-Q/3)

CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS (Unaudited) (from Apple, 10-Q/1)

CONDENSED CONSOLIDATED BALANCE SHEETS (Unaudited) (from Apple, 10-Q/1)

CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS (Unaudited) (from Apple, 10-Q/1)

Consolidated Balance Sheets (from Tesla, 10-Q/1)

Consolidated Balance Sheets (from Tesla, 10-K/2021)

Consolidated Statements of Operations (from Tesla, 10-Q/1)

Consolidated Statements of Cash Flows (from Tesla, 10-Q/1)

Looks like there are some common titles in different company's financial statements (regardless of upper-case or lower-case)

Get the report's date:

In ix:nonnumeric tag. But different format were found! (All in the tag or nested in tag). No format could be found!!
Get reporting date from url!! -> OK
Find table of three main financial statements:

After found the place of targeted title, find the nearest table. It might be the targeted table.
Pattern of three basic financial statements :
CONSOLIDATED STATEMENTS OF INCOME (or Consolidated Statements of Operations):

Three Months Ended, (N Months Ended; for !Q1)


# For executing this module first time, please execute the above program first, then "reports" are obtained.
# Build program of section 2
# Extract data from reports

# Settings of pandas's dataframe
report_data = []
report_index = []
report_column = []


# List of individual financial statement of specific quarter
report_df_list = []

# for report in reports:
#     print(report[1])
#     print(report[2])
#     print(check_report_type(report[0]))
    
    

# Find table for "Consolidated statements of operations (incomes)"
title_regex = re.compile("consolidated statements of operations|income")
#title_element = 





# Deprecated below!
# Read "CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS (Unaudited)"
# table_name = "CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS (Unaudited)"

# result = reports[0].find('div', string = table_name).findNext('div').findNext('div').findNext('div').findNext('table')
# print(result)
# display(pd.DataFrame(result, dtype = "object"))  # Very uglyand wrong!!


# report_df = pd.read_html(str(reports[0].find('div', string = table_name).findNext('div').findNext('div').findNext('div').findNext('table')))
# display(pd.DataFrame(report_df))

# check_report_type(reports[1])
